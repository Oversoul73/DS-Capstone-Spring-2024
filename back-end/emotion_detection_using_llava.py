# -*- coding: utf-8 -*-
"""emotion-detection-using-llava (4).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ExpYwYVJXhNQFDI5bBOXwuvZr70CnQne
"""

import numpy as np
import pandas as pd
import os
import re

# List to store file paths
file_paths = []

# Walk through the directory
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        # Append the file path to the list
        file_paths.append(os.path.join(dirname, filename))

# Create DataFrame
df = pd.DataFrame(file_paths, columns=['image'])

# Use regex to extract emotion from file path
df['emotion'] = df['image'].str.extract(r'/([^/]+)/[^/]+\.png$')

# Rename 'happy' to 'happy' in the 'emotion' column
df['emotion'] = df['emotion'].replace({'happy': 'happy'})

# Display the DataFrame
print(df.head())

df.count()

!pip install -q -U transformers==4.37.2
!pip install -q bitsandbytes==0.41.3 accelerate==0.25.0

import requests
from PIL import Image

image_url = "https://llava-vl.github.io/static/images/view.jpg"
image = Image.open(requests.get(image_url, stream=True).raw)
image

import torch
from transformers import BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16
)

from transformers import pipeline

model_id = "llava-hf/llava-1.5-7b-hf"

pipe = pipeline("image-to-text", model=model_id, model_kwargs={"quantization_config": quantization_config})

max_new_tokens = 200
prompt = "USER: <image>What is the emotion detected in this image?\nASSISTANT:"

outputs = pipe(image, prompt=prompt, generate_kwargs={"max_new_tokens": 200})

import IPython
from IPython.display import display
IPython.display.Image(filename='../input/emotion-detection-fer/train/angry/im0.png')

outputs1 = pipe("../input/emotion-detection-fer/train/angry/im0.png", prompt=prompt, generate_kwargs={"max_new_tokens": 200})

print(outputs1[0]["generated_text"])

import re

pattern = r'(?s)ASSISTANT: (.*)'

matches = re.findall(pattern, outputs1[0]["generated_text"])

result=matches[0]

print(result)

outputs2 = pipe("../input/emotion-detection-fer/train/sad/im0.png", prompt=prompt, generate_kwargs={"max_new_tokens": 200})

IPython.display.Image(filename='../input/emotion-detection-fer/train/sad/im0.png')

print(outputs2[0]["generated_text"])

pattern = r'(?s)ASSISTANT: (.*)'

matches = re.findall(pattern, outputs2[0]["generated_text"])

result=matches[0]

print(result)

# Sort the DataFrame by the 'emotion' column
df_sorted = df.sort_values(by='emotion')

# Group the DataFrame by the 'emotion' column
grouped = df_sorted.groupby('emotion')

# Initialize an empty list to store selected samples
selected_samples = []

# Iterate over each group and select 50 samples from each
for _, group_df in grouped:
    selected_samples.append(group_df.sample(n=50, random_state=42))  # Select 50 samples from each group

# Concatenate the selected samples back into a DataFrame
df_selected = pd.concat(selected_samples)

# Reset index of the resulting DataFrame
df_selected.reset_index(drop=True, inplace=True)

# Display the resulting DataFrame
print(df_selected.head())

df_selected.count()

import tqdm

# List to store predicted emotions
predicted_emotions = []

pattern = r'(?s)ASSISTANT: (.*)'

# Iterate over each image path in the DataFrame with a progress bar
for i, image_path in tqdm.tqdm(enumerate(df_selected['image']), total=len(df_selected)):
    # Construct prompt for the current image
    prompt = f"USER: <image>What is the emotion detected in this image, give output in only one word, the valid classification categories are: angry, disgusted, fearful, happy, neutral, sad, surprised ?\n\nASSISTANT:"

    # Generate response using the model
    outputs = pipe(image_path, prompt=prompt, generate_kwargs={"max_new_tokens": 200})

    # Extract predicted emotion from the generated text
    matches = re.findall(pattern, outputs[0]["generated_text"])

    result=matches[0].lower()
    predicted_emotion = result # Assuming emotion is the first word

    # Append predicted emotion to the list
    predicted_emotions.append(predicted_emotion)

# Add predicted emotions to the DataFrame as a new column
df_selected['predicted emotion'] = predicted_emotions

# Display the updated DataFrame
print(df_selected.head())

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Compute the confusion matrix
conf_matrix = confusion_matrix(df_selected['emotion'], df_selected['predicted emotion'])

# Get unique emotions
emotions = sorted(df_selected['emotion'].unique())

# Plot the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', xticklabels=emotions, yticklabels=emotions)
plt.xlabel('Predicted Emotion')
plt.ylabel('Actual Emotion')
plt.title('Confusion Matrix')
plt.show()

import tqdm

# List to store predicted emotions
predicted_emotions = []

pattern = r'(?s)ASSISTANT: (.*)'

# Iterate over each image path in the DataFrame with a progress bar
for i, image_path in tqdm.tqdm(enumerate(df['image']), total=len(df)):
    # Construct prompt for the current image
    prompt = f"USER: <image>What is the emotion detected in this image, give output in only one word, the valid classification categories are: angry, disgusted, fearful, happy, neutral, sad, surprised ?\n\nASSISTANT:"

    # Generate response using the model
    outputs = pipe(image_path, prompt=prompt, generate_kwargs={"max_new_tokens": 200})

    # Extract predicted emotion from the generated text
    matches = re.findall(pattern, outputs[0]["generated_text"])

    result=matches[0].lower()
    predicted_emotion = result # Assuming emotion is the first word

    # Append predicted emotion to the list
    predicted_emotions.append(predicted_emotion)

# Add predicted emotions to the DataFrame as a new column
df['predicted emotion'] = predicted_emotions

# Display the updated DataFrame
print(df.head())

df.count()

# Compute the confusion matrix
conf_matrix1 = confusion_matrix(df['emotion'], df['predicted emotion'])

# Get unique emotions
emotions = sorted(df['emotion'].unique())

# Plot the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix1, annot=True, cmap='Blues', fmt='g', xticklabels=emotions, yticklabels=emotions)
plt.xlabel('Predicted Emotion')
plt.ylabel('Actual Emotion')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score

# Get unique emotions
emotions = sorted(df['emotion'].unique())

# Initialize dictionaries to store metrics for each emotion
precision = {}
recall = {}
accuracy = {}
f1 = {}

# Calculate metrics for each emotion
for emotion in emotions:
    # Indices corresponding to the current emotion
    idx = df['emotion'] == emotion

    # Calculate precision, recall, accuracy, and F1-score for the current emotion
    precision[emotion] = precision_score(df[idx]['emotion'], df[idx]['predicted emotion'], average='weighted')
    recall[emotion] = recall_score(df[idx]['emotion'], df[idx]['predicted emotion'], average='weighted', zero_division=1)
    accuracy[emotion] = accuracy_score(df[idx]['emotion'], df[idx]['predicted emotion'])
    f1[emotion] = f1_score(df[idx]['emotion'], df[idx]['predicted emotion'], average='weighted')

# Print metrics for each emotion
for emotion in emotions:
    print(f'Emotion: {emotion}')
    print(f'Precision: {precision[emotion]}')
    print(f'Recall: {recall[emotion]}')
    print(f'Accuracy: {accuracy[emotion]}')
    print(f'F1-score: {f1[emotion]}')
    print()

# Compute True Positives (TP), False Positives (FP), False Negatives (FN)
TP = np.diag(conf_matrix1)
FP = np.sum(conf_matrix1, axis=0) - TP
FN = np.sum(conf_matrix1, axis=1) - TP

# Compute True Negatives (TN)
num_classes = len(emotions)
TN = []
for i in range(num_classes):
    temp = np.delete(conf_matrix1, i, 0)    # delete ith row
    temp = np.delete(temp, i, 1)  # delete ith column
    TN.append(sum(sum(temp)))

# Compute Precision, Recall, and F1-score
precision = TP / (TP + FP)
recall = TP / (TP + FN)
f1_score = 2 * (precision * recall) / (precision + recall)

# Compute Accuracy
accuracy = np.sum(TP) / np.sum(conf_matrix1)

# Print metrics
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1_score)
print("Accuracy:", accuracy)

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Create a figure and axis object
plt.figure(figsize=(10, 8))

# Iterate over each emotion
for i, emotion in enumerate(emotions):
    # Compute binary label for the current emotion
    y_true_binary = (df['emotion'] == emotion).astype(int)

    # Compute predicted probability for the current emotion
    y_score = (df['predicted emotion'] == emotion).astype(int)

    # Compute ROC curve
    fpr, tpr, _ = roc_curve(y_true_binary, y_score)

    # Compute AUC
    roc_auc = auc(fpr, tpr)

    # Plot ROC curve
    plt.plot(fpr, tpr, lw=2, label=f'{emotion} (AUC = {roc_auc:.2f})')

# Set plot properties
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Each Emotion')
plt.legend(loc="lower right")
plt.show()

# Save DataFrame to a CSV file
df.to_csv('/kaggle/working/emotion_data.csv', index=False)

# Use Kaggle's utility to create a download link
from IPython.display import FileLink
FileLink('/kaggle/working/emotion_data.csv')